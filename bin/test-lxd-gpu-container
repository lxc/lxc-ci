#!/bin/sh
set -eu

waitSnapdSeed() (
  set +x
  for i in $(seq 60); do # Wait up to 60s.
    if systemctl show snapd.seeded.service --value --property SubState | grep -qx exited; then
      return 0 # Success.
    fi

    sleep 1
  done

  echo "snapd not seeded after ${i}s"
  return 1 # Failed.
)

cleanup() {
    echo ""
    if [ "${FAIL}" = "1" ]; then
        echo "Test failed"
        exit 1
    fi

    echo "Test passed"
    exit 0
}

FAIL=1
trap cleanup EXIT HUP INT TERM

# Wait for snapd seeding
waitSnapdSeed

# Configure to use the proxy
curl -s http://canonical-lxd.stgraber.org/config/snapd.sh | sh

# Install LXD
while [ -e /usr/bin/lxd ]; do
    apt-get remove --purge --yes lxd lxd-client lxcfs liblxc1
done
apt-get remove --purge cloud-init --yes
snap remove lxd || true
snap install lxd --channel=latest/edge
lxd waitready --timeout=300

# Check that NVIDIA is installed
nvidia-smi

# Configure LXD
lxc storage create default zfs
lxc profile device add default root disk path=/ pool=default
lxc network create lxdbr0
lxc profile device add default eth0 nic network=lxdbr0 name=eth0

# Launch a test container
echo "==> Launching a test container"
lxc launch images:ubuntu/20.04/cloud c1
sleep 10

# Confirm no GPU
echo "==> Testing with no GPU"
! lxc exec c1 -- ls -lh /dev/dri/ || false

# Validate with one GPU
echo "==> Testing with one GPU"
lxc config device add c1 gpu0 gpu id=0
[ "$(lxc exec c1 -- ls /dev/dri/ | grep -c card)" = "1" ] || false

# Validate with two GPus
echo "==> Testing with two GPUs"
lxc config device add c1 gpu1 gpu id=1
[ "$(lxc exec c1 -- ls /dev/dri/ | grep -c card)" = "2" ] || false

# Validate with all remove
echo "==> Testing with no GPU"
lxc config device remove c1 gpu0
lxc config device remove c1 gpu1
[ "$(lxc exec c1 -- ls /dev/dri/ | grep -c card)" = "0" ] || false

# Validate with all GPUs
echo "==> Testing with all GPUs"
lxc config device add c1 gpus gpu
[ "$(lxc exec c1 -- ls /dev/dri/ | grep -c card)" = "3" ] || false

# Test nvidia runtime
echo "==> Testing nvidia runtime"
! lxc exec c1 -- nvidia-smi || false
lxc stop c1
lxc config set c1 nvidia.runtime true
lxc start c1
lxc exec c1 -- nvidia-smi

# Test with PCI addresses
echo "==> Testing PCI address selection"
lxc config device remove c1 gpus
lxc config device add c1 gpu1 gpu pci=0000:06:00.0
lxc config device add c1 gpu2 gpu pci=0000:07:00.0
[ "$(lxc exec c1 -- ls /dev/dri/ | grep -c card)" = "2" ] || false
lxc exec c1 -- nvidia-smi

# Test with vendor
echo "==> Testing PCI vendor selection"
lxc config device remove c1 gpu1
lxc config device remove c1 gpu2
lxc config device add c1 gpus gpu vendorid=10de
[ "$(lxc exec c1 -- ls /dev/dri/ | grep -c card)" = "2" ] || false
lxc exec c1 -- nvidia-smi

# Test with vendor and product
echo "==> Testing PCI vendor and product selection"
lxc config device remove c1 gpus
lxc config device add c1 gpus gpu vendorid=1af4 productid=0010
[ "$(lxc exec c1 -- ls /dev/dri/ | grep -c card)" = "1" ] || false

FAIL=0
