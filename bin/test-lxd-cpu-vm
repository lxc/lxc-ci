#!/bin/sh
set -eux

waitSnapdSeed() (
  set +x
  for i in $(seq 60); do # Wait up to 60s.
    if systemctl show snapd.seeded.service --value --property SubState | grep -qx exited; then
      return 0 # Success.
    fi

    sleep 1
  done

  echo "snapd not seeded after ${i}s"
  return 1 # Failed.
)

cleanup() {
    echo ""
    if [ "${FAIL}" = "1" ]; then
        echo "Test failed"
        exit 1
    fi

    echo "Test passed"
    exit 0
}

architecture="$(uname -m)"

if [ "${architecture}" != "x86_64" ] && [ "${architecture}" != "s390x" ]; then
  echo "Skipping test as CPU hotplugging not supported on ${architecture}"
fi

FAIL=1
trap cleanup EXIT HUP INT TERM

# Wait for snapd seeding
waitSnapdSeed

# Configure to use the proxy
curl -s http://canonical-lxd.stgraber.org/config/snapd.sh | sh

# Configure for ceph use
curl -s http://canonical-lxd.stgraber.org/config/ceph.sh | sh

# Install LXD
while [ -e /usr/bin/lxd ]; do
    apt-get remove --purge --yes lxd lxd-client lxcfs liblxc1
done
apt-get remove --purge cloud-init --yes
snap remove lxd || true
snap install lxd --channel=latest/edge
lxd waitready --timeout=300

waitVMAgent() (
  set +x
  # shellcheck disable=SC3043
  local vmName="$1"
  for i in $(seq 90) # Wait up to 90s.
  do
    if lxc info "${vmName}" | grep -qF 127.0.0.1; then
      return 0 # Success.
    fi

    sleep 1
  done

  echo "VM ${vmName} agent not running after ${i}s"
  return 1 # Failed.
)

# Configure LXD
lxc network create lxdbr0
lxc profile device add default eth0 nic network=lxdbr0

poolName="vmpool$$"
poolDriver=dir

echo "==> Create storage pool using driver ${poolDriver}"
lxc storage create "${poolName}" "${poolDriver}"

echo "==> Create ephemeral VM and boot"
lxc launch images:ubuntu/22.04 v1 --vm -s "${poolName}" --ephemeral
waitVMAgent v1
lxc info v1

# Get number of CPUs
# shellcheck disable=SC2010
cpuCount="$(ls /sys/devices/system/cpu | grep -Ec 'cpu[[:digit:]]+')"

# VMs should have only 1 CPU per default
[ "$(lxc exec v1 -- ls /sys/devices/system/cpu | grep -Ec 'cpu[[:digit:]]+')" -eq "1" ]

# Set valid CPU limits (low to high)
for i in $(seq 2 "${cpuCount}"); do
  lxc config set v1 limits.cpu="${i}"
  [ "$(lxc exec v1 -- ls /sys/devices/system/cpu | grep -Ec 'cpu[[:digit:]]+')" -eq "${i}" ]
done

# Try setting more CPUs than available
! lxc config set v1 limits.cpu="$(( cpuCount + 1 ))" || false

# Set valid CPU limits (high to low)
for i in $(seq "${cpuCount}" -1 1); do
  lxc config set v1 limits.cpu="${i}"
  [ "$(lxc exec v1 -- ls /sys/devices/system/cpu | grep -Ec 'cpu[[:digit:]]+')" -eq "${i}" ]
done

# Try doing pinning while VM is running (shouldn't work)
! lxc config set v1 limits.cpu=1,2 || false

# Set max CPU count
lxc config set v1 limits.cpu="${cpuCount}"
[ "$(lxc exec v1 -- ls /sys/devices/system/cpu | grep -Ec 'cpu[[:digit:]]+')" -eq "${cpuCount}" ]

# Unset CPU limit
lxc config unset v1 limits.cpu

# Unsetting the limit should leave the VM with 1 CPU
[ "$(lxc exec v1 -- ls /sys/devices/system/cpu | grep -Ec 'cpu[[:digit:]]+')" -eq "1" ]

echo "==> Stopping and deleting ephemeral VM"
# Stop VM and check its deleted.
lxc stop -f v1
! lxc info v1 || false

lxc profile device remove default eth0

echo "==> Deleting storage pool"
lxc storage delete "${poolName}"

echo "==> Deleting storage pool"
lxc network delete lxdbr0

FAIL=0
